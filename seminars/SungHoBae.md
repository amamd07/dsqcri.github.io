---
layout: page
title (1): Vision Perception Models and Their Applications to Image Processing and Computer Vision
title (2): An Accurate View Generation from a Single Image using Convolutional Neural Networks
permalink: /seminars/SungHoBae/
date: March 08, 2017
---

## 1) Vision Perception Models and Their Applications to Image Processing and Computer Vision
## 2) An Accurate View Generation from a Single Image using Convolutional Neural Networks


### Speaker:

[Sung-Ho Bae]()

### Abstract:

In this seminar, I will present two short talks. The first presentation is entitled 'Vision Perception Models and Their Applications to Image Processing and Computer Vision'. In this presentation, I will present low-level and high-level vision-perception models and their applications to image processing (video compression and single-image super-resolution) and computer vision (single-object visual tracking). The main motivation of this work is that, although mean squared error (MSE) has often been used as objective functions in the conventional image processing algorithms, it is not strongly correlated with perceived visual quality. Therefore, I proposed perceptual-friendly objective quality assessment metrics based on low-level vision perception models and use them as objective functions in image processing problems. 

Experimental results show that objective quality assessment metrics-based optimization frameworks can produce higher visual quality compared to MSE based ones. The second presentation is ' An Accurate View Generation from a Single Image using Convolutional Neural Network' which coincide with virtual reality content generation for immersive streaming service of 2022 Qatar World-cup. The proposed method is an end-to-end method based on convolutional neural networks (CNN), which takes input as a single left view image and outputs its corresponding right-view image. Experimental results show that the proposed view generation runs in real-time with one Titan X GPU and can produce good quality stereoscopic images from single images. This work was submitted to CVPR 2017.